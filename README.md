# ğŸš€ LangChain PRO-Mode Demo with Google Gemini 2.0 Flash

[![Google AI Studio](https://img.shields.io/badge/Google%20AI%20Studio-Gemini%202.0%20Flash-blueviolet)](https://ai.google.dev/)
[![LangChain](https://img.shields.io/badge/LangChain-Framework-brightgreen)](https://python.langchain.com/)
[![Python 3.12](https://img.shields.io/badge/Python-3.12-blue)](https://www.python.org/)

> LangChainê³¼ Googleì˜ **Gemini 2.0 Flash** ëª¨ë¸ì„ í™œìš©í•˜ì—¬,  
> ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ê±°ì³ ìµœì ì˜ ê²°ê³¼ë¬¼ì„ ìƒì„±í•˜ëŠ” "PRO-Mode" ì˜ˆì‹œì…ë‹ˆë‹¤.  
> ë²ˆì—­ â†’ ì´ˆê¸° ì‘ë‹µ â†’ ê°œì„  â†’ ì¬ë²ˆì—­ì˜ ìˆœì°¨ì ì¸ ê³¼ì •ì„ í†µí•´,  
> LLMì´ ê°€ì¥ ì í•©í•œ ë‹µë³€ì„ ë‹¨ê³„ì ìœ¼ë¡œ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.

## âœ¨ ì†Œê°œ (Introduction)

- **PRO-Modeë€?**
    - ë‹¨ìˆœí•œ ë‹¨ì¼ í˜¸ì¶œì´ ì•„ë‹Œ, ì—¬ëŸ¬ ì°¨ë¡€ì˜ ì¬ê·€ì (Recurrent) í˜¸ì¶œì„ í†µí•´ ì‘ë‹µì„ ì ì§„ì ìœ¼ë¡œ ê°œì„ (Refine)í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
    - ì´ í”„ë¡œì íŠ¸ì—ì„œëŠ” Time Tracking, ì‚¬ìš©ì ì…ë ¥ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­/ì¬ë²ˆì—­, ì‘ë‹µ ê²°ê³¼ì˜ ë°˜ë³µì  ê°œì„  ê¸°ë²• ë“±ì„ ì‹œì—°í•©ë‹ˆë‹¤.

- **ì‚¬ìš©ëœ ê¸°ìˆ  ìŠ¤íƒ**
    1.  **LangChain**: LLM í˜¸ì¶œ ë° ì²´ì¸ êµ¬ì„±ì„ ìœ„í•œ íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
    2.  **Google Generative AI**: Gemini 2.0 Flash ëª¨ë¸ API (íŒŒì´ì¬ wrapper: `langchain-google-genai`)
    3.  **Python-dotenv**: `.env` íŒŒì¼ì—ì„œ API í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë“œ
    4.  **Miniconda** (ë˜ëŠ” Anaconda): íŒŒì´ì¬ ê°€ìƒ í™˜ê²½ ê´€ë¦¬

## ğŸŒŸ ì£¼ìš” ê¸°ëŠ¥ (Features)

1.  **ì–¸ì–´ ìë™ ë²ˆì—­**
    -   ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ LLM ì¹œí™”ì ì¸ ì–¸ì–´(ì˜ì–´)ë¡œ ë²ˆì—­
    -   ìµœì¢… ê²°ê³¼ë¬¼ì„ ë‹¤ì‹œ ì‚¬ìš©ì ëª¨êµ­ì–´ë¡œ ì¬ë²ˆì—­

2.  **ë‹¤ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤**
    -   **ë²ˆì—­ í˜ì´ì¦ˆ** â†’ **ìµœì´ˆ ì‘ë‹µ í˜ì´ì¦ˆ** â†’ **ê°œì„  í˜ì´ì¦ˆ**(ë°˜ë³µ) â†’ **ì‚¬ìš©ì ì–¸ì–´ ì‘ë‹µ í˜ì´ì¦ˆ**
    -   ìµœëŒ€ 5~10íšŒ í˜¹ì€ ê·¸ ì´ìƒì˜ ì¬ê·€ ê°œì„  ìš”ì²­ ê°€ëŠ¥

3.  **ì‹œê°„ ì¶”ì  (Thinking í‘œì‹œ)**
    -   `Thread`ì™€ `Event`ë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ì´ ìƒê°í•˜ëŠ” ì‹œê°„ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í„°ë¯¸ë„ì— í‘œê¸°
    -   ì‚¬ìš©ìì—ê²Œ ë§ˆì¹˜ ëŒ€í˜• ì¶”ë¡ í˜• ëª¨ë¸ì´ ì˜¤ëœ ì‹œê°„ ë™ì•ˆ ìƒê°í•˜ëŠ” ë“¯í•œ ì¸í„°ë™ì…˜ ì œê³µ

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì¤€ë¹„ (Installation)

ì•„ë˜ ì˜ˆì‹œ í™˜ê²½ì€ Python 3.12 ê¸°ì¤€ì…ë‹ˆë‹¤.  ë‹¤ë¥¸ ë²„ì „ì´ì–´ë„ `langchain` í˜¸í™˜ì„±ë§Œ ë§ë‹¤ë©´ ëŒ€ë¶€ë¶„ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.

1.  **Miniconda/Anaconda ì„¤ì¹˜**
    -   [Anaconda.com/download](https://www.anaconda.com/download/)ì—ì„œ ì§ì ‘ ì„¤ì¹˜
    -   í˜¹ì€ ê¸°ì¡´ì— `conda`ê°€ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ë©´ ì´ ë‹¨ê³„ ìƒëµ

2.  **ê°€ìƒ í™˜ê²½ ìƒì„± ë° í™œì„±í™”**

    ```bash
    conda create --name my_pro python=3.12 pip
    conda activate my_pro
    ```

3.  **í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜**

    ```bash
    pip install python-dotenv
    pip install langchain
    # Gemini API ì‚¬ìš© ì‹œ
    pip install "langchain-google-genai"
    # ì¶”ê°€ë¡œ OpenAI/Anthropic/ë“±ì„ ì‚¬ìš©í•œë‹¤ë©´
    pip install "langchain-openai"
    pip install "langchain-anthropic"
    ```

4.  **`.env` íŒŒì¼ ì„¤ì •**
    -   ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì— `.env` íŒŒì¼ ìƒì„± í›„ ì•„ë˜ì™€ ê°™ì´ API í‚¤ë¥¼ ì…ë ¥

        ```
        GOOGLE_API_KEY=YOUR_GEMINI_API_KEY
        ```

    -   Google Cloud Generative AI (Gemini) í‚¤ê°€ ì—†ëŠ” ê²½ìš°, [AI Studio](https://makersuite.google.com/app/apikey) ë“±ì„ í†µí•´ ë°œê¸‰ë°›ìœ¼ì„¸ìš”.

## ğŸš€ ì‚¬ìš© ë°©ë²• (Usage)

1.  ì´ ë ˆí¬ë¥¼ í´ë¡  í˜¹ì€ ì½”ë“œë¥¼ ë³µì‚¬ í›„, `main.py` (íŒŒì¼ëª… ììœ ) ìƒì„±
2.  ì•„ë˜ ì˜ˆì‹œ ì½”ë“œë¥¼ ë¶™ì—¬ë„£ê³  `.env`ê°€ ì¤€ë¹„ëœ ìƒíƒœì—ì„œ ì‹¤í–‰

    ```python
    # main.py

    # API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ì‘ì—…
    from dotenv import dotenv_values

    env = dotenv_values()

    # LLM ëª¨ë¸ ì…‹ì—…
    from langchain.chat_models import init_chat_model

    model = init_chat_model(
        model="gemini-2.0-flash",
        model_provider="google_genai",
        api_key=env["GOOGLE_API_KEY"],
    )


    # ì‹œê°„ ì¸¡ì • ìœ„í•œ ì‘ì—…
    from time import time, sleep
    import sys
    from threading import Thread, Event

    stop_time = Event()


    def show_time():
        start = time()
        while not stop_time.is_set():
            sys.stdout.write(f"\rThinking... {time() - start:.2f}s")
            sys.stdout.flush()
            sleep(0.1)


    # ë²ˆì—­ í”„ë¡¬í”„íŠ¸
    def prompt_translate(prompt, target_language):
        return f"""
        Accurately translate the following text into natural {target_language}.
        ```
        {prompt}
        ```
        Output only the perfectly translated text.
        """


    # ëª¨ë¸ ì–¸ì–´
    llm_language = "American English"
    # ì‚¬ìš©ì ì–¸ì–´
    user_language = "Korean"

    # ì‚¬ìš©ì ì…ë ¥
    request = input("User: ")

    # ì‹œê°„ ì¸¡ì • ìŠ¤ë ˆë“œ ì‹œì‘
    Thread(target=show_time, daemon=True).start()

    # 1. ë²ˆì—­ í˜ì´ì¦ˆ
    response = model.invoke(prompt_translate(request, llm_language)).content
    print(f'\nHmm.. The user said, "{response}"')

    # 2. ìµœì´ˆ ì‘ë‹µ í˜ì´ì¦ˆ
    response = model.invoke(request).content

    # 3. ê°œì„  í˜ì´ì¦ˆ
    for i in range(5):
        response = model.invoke(
            f"""
            request:
            ```
            {request}
            ```
            response:
            ```
            {response}
            ```
            Refine the response to perfectly match the request.
            Output only the plaintext response.
            Ask nothing; independently make all choices and output only the final result.
            Do not explain any refinements.
            """
        ).content

    # 4. ì‚¬ìš©ì ì–¸ì–´ ì‘ë‹µ í˜ì´ì¦ˆ
    print(f"\nRespond in the user's native language. '{user_language}'")
    response = model.invoke(prompt_translate(response, user_language)).content
    stop_time.set()

    # 5. ìµœì¢… ì‘ë‹µ í˜ì´ì¦ˆ
    print(f"\nAI: {response}")


    ```

3.  **ì‹¤í–‰**

    ```bash
    python main.py
    ```

4.  **í”„ë¡œê·¸ë¨ ë™ì‘**
    -   í„°ë¯¸ë„ì— `User:`ë¼ê³  ëœ¨ë©´, ì›í•˜ëŠ” ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì„ ì…ë ¥
    -   ëª¨ë¸ì´ `Thinkingâ€¦` ìƒíƒœë¡œ ì‹œê°„ ê²½ê³¼ë¥¼ í‘œì‹œí•˜ë©° ì‘ë‹µ ì¤€ë¹„
    -   ì˜ì–´ ë²ˆì—­ â†’ ì´ˆê¸° ì‘ë‹µ ìƒì„± â†’ 5íšŒ ê°œì„  â†’ ìµœì¢…ì ìœ¼ë¡œ í•œêµ­ì–´(ì‚¬ìš©ì ì–¸ì–´)ë¡œ ë³€í™˜
    -   ìµœì¢… ê²°ê³¼ë¬¼ì„ `AI: ...` í˜•ì‹ìœ¼ë¡œ ì¶œë ¥

## â“ FAQ / ìì£¼ ë¬»ëŠ” ì§ˆë¬¸

1.  **ì˜¤ë¥˜ ë°œìƒ ì‹œ**
    -   `.env` íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸ (`print(env)` ë“±ìœ¼ë¡œ ë””ë²„ê¹…)
    -   `conda` í™˜ê²½ì´ ì ì ˆíˆ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ ì¬í™•ì¸
    -   íŒ¨í‚¤ì§€ ë²„ì „ ì¶©ëŒ ì‹œ `pip install --upgrade <package_name>`ë¡œ ì—…ë°ì´íŠ¸
2.  **ì¶”ê°€ ëª¨ë¸ ì‚¬ìš©**
    -   Anthropic Claude, OpenAI GPT ì‹œë¦¬ì¦ˆ ë“±ì€ ê°ê° API í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ì•¼ í•©ë‹ˆë‹¤.
    -   `langchain-openai`, `langchain-anthropic` ë“±ì„ ì¶”ê°€ ì„¤ì¹˜ í›„, ë¹„ìŠ·í•œ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
    -   `main.py`ì—ì„œ `ChatGoogleGenerativeAI` ë¶€ë¶„ì„ í•´ë‹¹ ëª¨ë¸ì— ë§ê²Œ ìˆ˜ì •í•´ì•¼í•©ë‹ˆë‹¤. (ì˜ˆ: `ChatOpenAI`, `ChatAnthropic`)
3.  **ì¬ê·€(Refine) íšŸìˆ˜ ì¡°ì •**
    -   `for i in range(5):` ë¶€ë¶„ì˜ ìˆ«ìë¥¼ ì›í•˜ëŠ” ë§Œí¼ ëŠ˜ë¦¬ê±°ë‚˜ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    -   ë‹¨, ë„ˆë¬´ ë§ì´ ëŠ˜ë¦¬ë©´ API ë¹„ìš©ê³¼ ì‹œê°„ì´ ì¦ê°€í•˜ë‹ˆ ì£¼ì˜í•˜ì„¸ìš”.

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details (optional: ë¼ì´ì„ ìŠ¤ íŒŒì¼ì„ ì¶”ê°€í•  ê²½ìš°).

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. (optional: ê¸°ì—¬ ê´€ë ¨ ë‚´ìš©ì„ ì¶”ê°€í•  ê²½ìš°)